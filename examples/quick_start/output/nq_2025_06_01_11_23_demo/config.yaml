model2path:
    e5: intfloat/e5-base-v2
    bge: BAAI/bge-base-en-v1.5
    contriever: facebook/contriever
    llama2-7B-chat: meta-llama/Llama-2-7b-chat-hf
    llama2-7B: meta-llama/Llama-2-7b-hf
    llama2-13B: meta-llama/Llama-2-13b-hf
    llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
    llama3-1B-instruct: ~/nlp_project/meta-llama/Meta-Llama-3.2-1B-Instruct
    llama3-8B-instruct: meta-llama/Meta-Llama-3-8B-Instruct
model2pooling:
    e5: mean
    bge: cls
    contriever: mean
    jina: mean
    dpr: cls
method2index:
    e5: null
    bm25: null
    contriever: null
    clip:
        text: path/to/text_index
        image: path/to/image_index
data_dir: dataset/
save_dir: output/nq_2025_06_01_11_23_demo
gpu_id: 0,1,2,3
dataset_name: nq
split:
- test
test_sample_num: null
random_sample: false
seed: 2024
save_intermediate_data: true
save_note: demo
retrieval_method: e5
retrieval_model_path: intfloat/e5-base-v2
index_path: indexes/e5_Flat.index
multimodal_index_path_dict: null
faiss_gpu: false
corpus_path: indexes/general_knowledge.jsonl
instruction: null
retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: true
retrieval_query_max_length: 128
save_retrieval_cache: false
use_retrieval_cache: false
retrieval_cache_path: null
retrieval_pooling_method: mean
bm25_backend: bm25s
use_sentence_transformer: false
silent_retrieval: true
use_reranker: false
rerank_model_name: null
rerank_model_path: null
rerank_pooling_method: null
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 256
rerank_use_fp16: true
use_multi_retriever: false
multi_retriever_setting:
    merge_method: concat
    topk: 5
    rerank_model_name: null
    rerank_model_path: null
    retriever_list:
    -   retrieval_method: e5
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: intfloat/e5-base-v2
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
    -   retrieval_method: bm25
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: bm25
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: null
        rerank_model_path: null
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
framework: vllm
generator_model: llama3-1B-instruct
openai_setting:
    api_key: null
    base_url: null
generator_model_path: ~/nlp_project/meta-llama/Meta-Llama-3.2-1B-Instruct
generator_max_input_len: 2048
generator_batch_size: 2
generation_params:
    max_tokens: 32
    do_sample: false
use_fid: false
gpu_memory_utilization: 0.85
metrics:
- em
- f1
- acc
- precision
- recall
metric_setting:
    retrieval_recall_topk: 5
    tokenizer_name: gpt-4
save_metric_score: true
refiner_name: null
refiner_model_path: null
refiner_topk: 5
refiner_pooling_method: mean
refiner_encode_max_length: 256
refiner_max_input_length: 1024
refiner_max_output_length: 512
llmlingua_config:
    rate: 0.55
    condition_in_question: after_condition
    reorder_context: sort
    dynamic_context_compression_ratio: 0.3
    condition_compare: true
    context_budget: '+100'
    rank_method: longllmlingua
sc_config:
    reduce_ratio: 0.5
dataset_path: dataset/nq
gpu_num: 1
device: cuda

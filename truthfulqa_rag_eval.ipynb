{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8276de3",
      "metadata": {
        "id": "a8276de3"
      },
      "outputs": [],
      "source": [
        "!pip install flashrag-dev --pre --upgrade\n",
        "!pip install -U datasets\n",
        "!pip install sentence-transformers==3.4.1\n",
        "!pip install vllm==0.7.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wBiGeyA30jy0",
      "metadata": {
        "id": "wBiGeyA30jy0"
      },
      "outputs": [],
      "source": [
        "!pip install flashinfer-python==0.2.5\n",
        "!pip install litellm==1.68.2\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c6db76",
      "metadata": {
        "id": "a4c6db76"
      },
      "outputs": [],
      "source": [
        "!python3 -m nltk.downloader stopwords\n",
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e268572",
      "metadata": {
        "id": "0e268572"
      },
      "source": [
        "### Pull code from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf36e9cf",
      "metadata": {
        "id": "cf36e9cf"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data .config\n",
        "!git clone https://github.com/th-chew/cs605_project ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1308f9a",
      "metadata": {
        "id": "e1308f9a"
      },
      "source": [
        "### You will need to create a Hugging Face account to download the Llama 3.2 models. After creating an account, generate a token to be used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeebeba0",
      "metadata": {
        "id": "aeebeba0"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login --token hf_4ZkXJYbqjWQdVZcXzYwzYwzYwzYwzYwzYwz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a236c4c",
      "metadata": {
        "id": "2a236c4c"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli download meta-llama/Llama-3.2-3B-Instruct --local-dir meta-llama/Llama-3.2-3B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mik9SH8C17hB",
      "metadata": {
        "id": "mik9SH8C17hB"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli download loganchew/rbft_llama3 --local-dir loganchew/rbft_llama3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1173de8d",
      "metadata": {
        "id": "1173de8d"
      },
      "source": [
        "### Restart session after installing the packages because of numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f66e81",
      "metadata": {
        "id": "f3f66e81"
      },
      "outputs": [],
      "source": [
        "import json, argparse, datasets\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from eval.prompt import NaivePromptTemplate, MCQPromptTemplate\n",
        "from eval.metrics import metric_dict\n",
        "from flashrag.config import Config\n",
        "from flashrag.utils import get_generator\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "\n",
        "def load_data(data_path, args):\n",
        "    def load_psgs(item):\n",
        "        item['psgs'] = positive_psgs[item['qid']][:args.topk]\n",
        "\n",
        "        # Attack\n",
        "        if args.attack_position == 'random':\n",
        "            sample_value = np.random.rand(len(item['psgs']))\n",
        "            for id, v in enumerate(sample_value):\n",
        "                if v <= args.tau: # random mode\n",
        "                    cur_attack = np.random.choice(['neg', 'nsy', 'cf']) \\\n",
        "                        if args.passage_attack == 'mix' \\\n",
        "                            else args.passage_attack\n",
        "                    item['psgs'][id] = psgs_dict[cur_attack][item['qid']][id]\n",
        "\n",
        "        elif args.attack_position == 'top':\n",
        "            attack_topk = round(args.tau * len(item['psgs']))\n",
        "            for id in range(len(item['psgs'])):\n",
        "                if id < attack_topk: # top mode, only attack top psgs\n",
        "                    cur_attack = np.random.choice(['neg', 'nsy', 'cf']) \\\n",
        "                        if args.passage_attack == 'mix' \\\n",
        "                            else args.passage_attack\n",
        "                    item['psgs'][id] = psgs_dict[cur_attack][item['qid']][id]\n",
        "                else: # neglect bottom psgs\n",
        "                    break\n",
        "\n",
        "        elif args.attack_position == 'bottom':\n",
        "            keep_topk = round((1 - args.tau) * len(item['psgs']))\n",
        "            for id in range(len(item['psgs'])):\n",
        "                if id < keep_topk: # bottom mode, neglect top psgs\n",
        "                    continue\n",
        "                else: # only attack bottom psgs\n",
        "                    cur_attack = np.random.choice(['neg', 'nsy', 'cf']) \\\n",
        "                        if args.passage_attack == 'mix' \\\n",
        "                            else args.passage_attack\n",
        "                    item['psgs'][id] = psgs_dict[cur_attack][item['qid']][id]\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "\n",
        "        return item\n",
        "\n",
        "    dataset = datasets.load_dataset(\n",
        "        'json',\n",
        "        data_files = data_path + \"/sample.json\",\n",
        "    )['train']\n",
        "\n",
        "\n",
        "    with open(data_path + \"/posp.json\") as fr:\n",
        "        positive_psgs = {}\n",
        "        for line in fr:\n",
        "            line = json.loads(line)\n",
        "            positive_psgs[line['qid']] = line['pos_psgs']\n",
        "\n",
        "    neg_psgs, nsy_psgs, cf_psgs = {}, {}, {}\n",
        "    if args.passage_attack == 'neg' or args.passage_attack == 'mix':\n",
        "        with open(data_path + \"/negp.json\") as fr:\n",
        "            for line in fr:\n",
        "                line = json.loads(line)\n",
        "                neg_psgs[line['qid']] = line['neg_psgs']\n",
        "\n",
        "    if args.passage_attack == 'nsy' or args.passage_attack == 'mix':\n",
        "        with open(data_path + \"/nsyp.json\") as fr:\n",
        "            for line in fr:\n",
        "                line = json.loads(line)\n",
        "                nsy_psgs[line['qid']] = line['nsy_psgs']\n",
        "\n",
        "    if args.passage_attack == 'cf' or args.passage_attack == 'mix':\n",
        "        with open(data_path + \"/cfp.json\") as fr:\n",
        "            for line in fr:\n",
        "                line = json.loads(line)\n",
        "                cf_psgs[line['qid']] = line['cf_psgs']\n",
        "\n",
        "    psgs_dict = {\n",
        "        \"neg\" : neg_psgs,\n",
        "        \"nsy\" : nsy_psgs,\n",
        "        \"cf\" : cf_psgs\n",
        "    }\n",
        "\n",
        "    dataset = dataset.map(load_psgs)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def generate(generator, prompt_template, query_dataset, rerank=False, top_k_rerank=5):\n",
        "\n",
        "    if rerank:\n",
        "        ranked_psgs = []\n",
        "        reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
        "\n",
        "        for query, psgs in zip(query_dataset['query'], query_dataset['psgs']):\n",
        "            pairs = [[query, psg] for psg in psgs]\n",
        "\n",
        "            # Use sentence-transformers CrossEncoder for reranking\n",
        "            scores = reranker.predict(pairs)\n",
        "            top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "            psgs = [psgs[i] for i in top_indices[:top_k_rerank]]\n",
        "            ranked_psgs.append(psgs)\n",
        "\n",
        "        psgs = ranked_psgs\n",
        "\n",
        "    else:\n",
        "        psgs = query_dataset['psgs']\n",
        "\n",
        "    input_prompts = [\n",
        "        prompt_template.get_string(\n",
        "            question=query,\n",
        "            retrieval_result=psgs,\n",
        "            multiple_choice=\"\\n\".join(mcq_choice),\n",
        "        ) for query, psgs, mcq_choice in zip(query_dataset['query'], psgs, query_dataset['multiple_choice'])\n",
        "    ]\n",
        "\n",
        "    preds = generator.generate(input_prompts)\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def eval(args):\n",
        "    config_dict = {\"save_note\": \"eval\",\n",
        "                   \"gpu_id\": args.gpu_id,\n",
        "                   \"generator_model\": args.generator_model\n",
        "                }\n",
        "    config = Config(args.config_file, config_dict, )\n",
        "    print(config)\n",
        "    np.random.seed(config['seed'])\n",
        "    dataset = load_data(args.data_path, args)\n",
        "\n",
        "    dataset = dataset.filter(lambda example: example['from'] == 'truthful')\n",
        "\n",
        "    # print(f\"Loaded {len(dataset)} examples from {args.data_path}\")\n",
        "\n",
        "    # Filter first 10 rows from dataset for testing\n",
        "    # dataset = dataset.select(range(20))\n",
        "    # print first 10 rows of dataset\n",
        "    # print(dataset[:10])\n",
        "    \n",
        "    scorers = [metric_dict[metric](config) for metric in config['metrics']]\n",
        "\n",
        "    use_robustrag = args.use_robustrag\n",
        "    rerank = args.rerank\n",
        "    topk_rerank = args.topk_rerank\n",
        "\n",
        "    if use_robustrag:\n",
        "        from src.models import create_model\n",
        "        from src.defense import KeywordAgg\n",
        "\n",
        "        preds = []\n",
        "        print(\"Using RobustRAG\")\n",
        "        llm = create_model(args.model_name,cache_path=None)\n",
        "        model = KeywordAgg(llm, relative_threshold=args.alpha, absolute_threshold=args.beta, longgen=False, certify_save_path='')\n",
        "\n",
        "        if rerank:\n",
        "            ranked_psgs = []\n",
        "            reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L6-v2')\n",
        "            for query, psgs in zip(dataset['query'], dataset['psgs']):\n",
        "                pairs = [[query, psg] for psg in psgs]\n",
        "                scores = reranker.predict(pairs)\n",
        "                top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
        "                psgs = [psgs[i] for i in top_indices[:topk_rerank]]\n",
        "                ranked_psgs.append(psgs)\n",
        "            dataset_psgs = ranked_psgs\n",
        "        else:\n",
        "            dataset_psgs = dataset['psgs']\n",
        "\n",
        "        for query, psgs, mcq_choice in zip(dataset['query'], dataset_psgs, dataset['multiple_choice']):\n",
        "            # print(mcq_choice)\n",
        "            query_hints = model.generate_query_hints(query, psgs)\n",
        "            # print(query_hints)\n",
        "            query_prompt = llm.wrap_mcq_prompt_flashrag(query, psgs, hints=query_hints, multiple_choice=mcq_choice)                \n",
        "            response = llm.query(query_prompt)\n",
        "            # print(response)\n",
        "            # Extract first letter from response\n",
        "            response = response[0].strip().lower() if response else \"\"\n",
        "            # print(response)\n",
        "            preds.append(response)\n",
        "\n",
        "    else:\n",
        "        generator = get_generator(config)\n",
        "        prompt_template = MCQPromptTemplate(config)\n",
        "\n",
        "        preds = generate(generator, prompt_template, dataset, rerank, topk_rerank)\n",
        "\n",
        "    eval_results = [scorer.calculate_metric(preds, dataset['answer_alphabet'])[0] for scorer in scorers]\n",
        "    # print(eval_results)\n",
        "\n",
        "    with open(args.output_file, 'w') as fw:\n",
        "        fw.write(json.dumps({'result':eval_results})+\"\\n\")\n",
        "        for i, (q, a, p) in enumerate(zip(dataset['query'], dataset['answer'], preds)):\n",
        "            fw.write(json.dumps({i:{'query':q, 'answer':a, 'pred':p}})+'\\n')\n",
        "\n",
        "@dataclass\n",
        "class Args:\n",
        "    data_path: str = \"data/e5/test_data\"\n",
        "    gpu_id: str = \"0\"\n",
        "    topk: int = 5\n",
        "    rerank: bool = False\n",
        "    topk_rerank: int = 5\n",
        "    tau: float = 0.0\n",
        "    config_file: str = \"configs/eval.yaml\"\n",
        "    output_file: str = \"output/output.txt\"\n",
        "    attack_position: str = \"random\"\n",
        "    passage_attack: str = None\n",
        "    prompt_template: str = None\n",
        "\n",
        "    # RobustRAG parameters\n",
        "    model_name: str = 'llama3b'\n",
        "    defense_method: str = 'keyword'\n",
        "    alpha: float = 0.3\n",
        "    beta: float = 3.0\n",
        "    eta: float = 0.0\n",
        "    corruption_size: int = 1\n",
        "\n",
        "    use_robustrag: bool = False\n",
        "\n",
        "\n",
        "\n",
        "args = Args()\n",
        "args.config_file = \"configs/eval.yaml\"\n",
        "args.prompt_template = None\n",
        "\n",
        "# Old test\n",
        "# args.data_path = \"data/e5/old_test\"\n",
        "args.data_path = \"data/e5/test\"\n",
        "args.gpu_id = \"0\"\n",
        "args.topk = 10\n",
        "# Crossencoder reranker\n",
        "args.topk_rerank = 5\n",
        "args.tau = 0.0\n",
        "\n",
        "args.attack_position = \"random\"\n",
        "args.passage_attack = None\n",
        "args.generator_model = 'llama'\n",
        "\n",
        "# passage_attack is either None, \"mix\", \"cf\", \"nsy\", \"neg\". cf means counterfactual, nsy means noisy, neg means irrelevant. mix means random from all 3\n",
        "# randomness is set by a seed in config file, so it is deterministic.\n",
        "# attack_position is either \"random\", \"top\", \"bottom\". Note that \"random\" with tau=0 means no attack at all.\n",
        "\n",
        "attack_params_str = f\"{str(args.passage_attack)}_{str(args.attack_position)}_{str(args.tau)}\"\n",
        "\n",
        "# Vanilla RAG (Scenario 0)\n",
        "args.use_robustrag = False\n",
        "args.rerank = False\n",
        "args.output_file = f\"output/truthful_vanilla_rag_{attack_params_str}.json\"\n",
        "eval(args)\n",
        "\n",
        "# Use Vanilla RAG with CrossEncoder reranking (Scenario 1).\n",
        "args.use_robustrag = False\n",
        "args.rerank = True\n",
        "args.output_file = f\"output/truthful_crossencoder_rag_{attack_params_str}.json\"\n",
        "eval(args)\n",
        "\n",
        "# Use RobustRAG with CrossEncoder reranking (Scenario 2).\n",
        "args.use_robustrag = True\n",
        "args.rerank = True\n",
        "args.output_file = f\"output/truthful_crossencoder_robustrag_{attack_params_str}.json\"\n",
        "eval(args)\n",
        "\n",
        "# Use RbFt with CrossEncoder reranking (Scenario 3).\n",
        "# Change generator from llama to rbft_llama.\n",
        "args.use_robustrag = False\n",
        "args.generator_model = 'rbft_llama'\n",
        "args.rerank = True\n",
        "args.output_file = f\"output/truthful_crossencoder_rbft_{attack_params_str}.json\"\n",
        "eval(args)\n",
        "\n",
        "# Use RobustRAG with RbFt with CrossEncoder reranking (Scenario 4).\n",
        "# # Note that this is different from RobustRaG model_name\n",
        "args.generator_model = 'rbft_llama'\n",
        "args.use_robustrag = True\n",
        "args.model_name = 'rbft_llama'\n",
        "args.rerank = True\n",
        "args.output_file = f\"output/truthful_crossencoder_robustrag_rbft{attack_params_str}.json\"\n",
        "eval(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flashrag",
      "language": "python",
      "name": "flashrag"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
